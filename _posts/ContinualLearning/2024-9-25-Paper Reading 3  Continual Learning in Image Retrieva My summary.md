---
layout: post
title:  Paper Reading 3 Continual Learning in Image Retrieval-- My summary 
categories: [Paper Reading, Continual Learning, Image Retrieval  ] 
description: 
keywords: [Paper Reading, Continual Learning, Image Retrieval ] 

---



# Paper Reading 3  Continual Learning in Image Retrieval - My summary 



这里尝试进行进行总结看到的这几篇论文的思想。



首先这几篇论文要解决的都是 图像检索任务。 

什么是**图像检索（Image Retrieval，Visual search）**呢，也就是我们通常说的以图搜图。我们有一个**图库(Gallery)**，然后**输入一个图片(query)**，检索出最匹配的前几个图片。

图像检索系统是如何匹配呢？

图像经过**特征提取网络（feature extractor）**会转变为**特征空间（Representation Space）**的一个**特征向量（Feature Embedding）**。然后使用某种**距离度量 （Distance Metric）**如欧几里得距离、余弦相似度等，来衡量查询图像与图库中每张图像的特征向量之间的相似度。最后根据相似度将图库中的图像排序，返回与查询图像最相似的图像。

图像搜索任务和图像分类分类任务有什么区别的，应该来说很类似。看一下GPT的解答

>**图像检索**的任务是：给定一张**查询图像（Query Image）**，从一个**图库（Gallery）\**中检索出与查询图像\**最相似的图像**。
>
>- **目标**：图像检索的目标是找到与查询图像最相似的图像，通常通过计算查询图像与图库中所有图像之间的特征相似度来实现。
>- **过程**：
>  1. 提取查询图像和图库中所有图像的特征表示（Feature Embedding），通常是通过卷积神经网络（CNN）等模型来生成高维特征向量。
>  2. 使用某种距离度量（如欧几里得距离、余弦相似度等）来衡量查询图像与图库中每张图像的特征向量之间的相似度。
>  3. 根据相似度将图库中的图像排序，返回与查询图像最相似的图像。
>- **评价指标**：常用的评价指标包括**平均精度（mAP）**、**Top-K准确率**等。
>- **应用**：图像检索任务通常应用于**图像搜索引擎**、**内容推荐**、**身份验证（如人脸识别）**等场景。
>
>**图像分类**的任务是：给定一张图像，预测该图像所属的**类别标签**。
>
>- **目标**：图像分类的目标是为输入图像分配一个特定的类别标签，通常是在预定义的类别集合中选取一个标签。
>- **过程**：
>  1. 提取输入图像的特征表示，通常使用卷积神经网络（CNN）来提取图像的高维特征。
>  2. 通过一个分类器（如全连接层+Softmax函数），预测该图像属于某个特定类别。
>  3. 模型根据预测的概率分布输出最可能的类别。
>- **评价指标**：常用的评价指标包括**分类准确率（Accuracy）**、**混淆矩阵（Confusion Matrix）**、**Precision、Recall、F1 Score**等。
>- **应用**：图像分类通常应用于**物体识别**、**垃圾邮件检测**、**医疗影像分析**、**自动驾驶**等领域。
>
> **图像检索和图像分类的不同点**
>
>- **任务目标**：
>  - **图像分类**：目标是为一张输入图像分配一个预定义的类别标签，解决的是**分类问题**。
>  - **图像检索**：目标是从图库中找出与查询图像**相似的图像**，解决的是**相似度匹配问题**。
>- **结果输出**：
>  - **图像分类**：模型输出一个类别标签或一组类别的概率分布。
>  - **图像检索**：模型返回一个图像集合，按与查询图像的相似度排序。
>- **数据依赖性**：
>  - **图像分类**通常要求数据集是**有标签**的，即每张图像都带有明确的类别标签。
>  - **图像检索**不一定需要标签，通常只需要图像本身，并通过特征相似性进行匹配。
>- **评价标准**：
>  - **图像分类**主要以准确率（Accuracy）为评价标准，强调的是类别预测的准确性。
>  - **图像检索**主要使用检索精度（mAP）等指标，强调的是检索结果的排序和相关性。
>- **计算方式**：
>  - **图像分类**需要通过训练学习一个分类器来映射图像到特定的类别。
>  - **图像检索**更多依赖于图像的特征表示和距离度量，主要关注如何定义图像之间的相似性。
>
>

但是很多图像检索模型依旧是有着 特征提取器 和分类器，那么为什么这些图像检索模型依旧有着分类器呢？

在许多图像检索的研究中，研究者会首先使用图像分类任务对这些模型进行预训练（利用标注好的数据集），从而学习到良好的特征表示。然后在检索任务中，研究者可以移除模型的分类器部分，只使用其卷积层（特征提取器）来提取图像特征并进行检索。虽然图像检索的最终目标不是分类，但**特征提取器的设计和训练**常常是借助于分类任务完成的，特征提取器和分类器的概念共享同一套基础模型。

按着上面的表述，图像检索任务其实不需要模型输出一个确定的标签，但是需要整个 gallery 下所有图片的特征表示，这样才能进行距离的度量。

这个特征表示是保存下来的吗，还是将整个图库放进 特征提取器计算出来，这样岂不是每次查询都要进行一次计算？

>在图像检索任务中，通常采用预先计算和存储图库（gallery）中所有图像的特征表示来加速检索过程。具体来说，图像检索系统的执行通常分为**离线阶段**和**在线阶段**：
>
>离线阶段：特征提取与存储
>
>- **特征提取**：在离线阶段，系统会将图库中所有图像经过特征提取网络（例如基于卷积神经网络的特征提取器）计算出每张图像的**特征向量**（Feature Embedding）。
>- **存储特征**：这些特征向量通常会被**存储**到一个特征数据库中。这些向量的存储可以是简单的数值存储，也可以通过优化后的数据结构（如倒排索引或图结构）来加快后续的相似度计算。
>
>这种离线预处理的方式是为了避免在每次查询时都重新对整个图库进行特征提取，从而显著节省计算资源和时间。
>
>在线阶段：特征匹配与检索
>
>- **查询图像的特征提取**：当用户输入一张**查询图像（query image）**时，系统会使用同样的特征提取网络来计算该查询图像的**特征向量**。
>- **相似度计算**：然后，系统将查询图像的特征向量与图库中所有预存的特征向量进行相似度计算，通常使用欧几里得距离或余弦相似度等度量方法。
>- **排序与返回结果**：系统根据相似度对图库中的图像进行排序，并返回与查询图像最相似的图像集合。
>
>为什么使用预先计算的特征表示？
>
>- **效率**：如果每次检索时都需要对整个图库的所有图像进行特征提取，这将消耗大量计算资源，尤其是对于包含数百万图像的大型图库，计算代价非常高。而通过离线阶段预先计算并存储图库的特征，在线检索只需要对查询图像进行一次特征提取，然后进行高效的向量相似度计算，大大提高了系统的响应速度。
>- **实时性**：图像检索系统通常要求对用户输入的查询进行**实时**反馈。预先计算特征并存储下来，可以让在线阶段的计算主要集中在特征向量之间的匹配和排序上，这个过程的计算量较小，因此能够实现快速响应。
>
>特征表示的存储与优化
>
>- **数据库管理**：这些特征表示通常会存储在**数据库**中，比如基于向量存储的数据库（如Faiss、Annoy等），这些数据库被专门设计用来进行高效的相似度检索。
>- **近似最近邻搜索（ANN）**：在非常大的图库中，为了进一步提高检索效率，可以使用**近似最近邻（Approximate Nearest Neighbor, ANN）**搜索算法。这些算法可以显著加快相似度计算的速度，通常通过构建特殊的数据结构（如k-d树、LSH，或基于图的索引）来进行近似的相似向量搜索，从而提高效率。
>
>小结
>
>综上所述，图像检索系统通常通过**离线阶段预先计算图库特征**，并在**在线阶段进行快速相似度计算**来实现高效检索。这种设计能够避免每次查询时重复计算图库特征，显著提高了系统的检索效率和响应速度。
>
>如果每次都重新计算整个图库的特征，将会使图像检索变得非常缓慢和不切实际，特别是对于大规模图像集合。因此，预存特征是当前大部分图像检索系统中普遍采用的优化方法。
>
>

所以数据库中存储的是根据某个特征提取器将gallery中的所有图片提取得到的特征。



所以就有了以下问题，如果现在再数据库中要新加入一批数据，比如从未出现过的类，那么相应的需要进行训练更新 特征提取器 ，来更好地提取特征。 但是 如同上述表述，数据库保存的更新之前的这些特征可能就没法用了，

所以需要将加入新的类之后的 gallery中的所有图片重新提取一遍特征，再进行保存到数据库中。这个过程就是 **re-indexing** , 也就是将所有图片重新提取特征，建立索引(index)表。

那么毫无疑问这就带来了巨大的消耗和浪费。 

那么怎么解决这个问题呢，

如果之前数据库中的特征 即使在新加入类之后，还能用就好了。也就是说，这个时候，新的数据和旧的数据的特征最好处于相同的特征空间，并且能够使用之前的度量来进行比较关系，且新的特征不会混到旧的样本中去。

但这个很难，问题就在于 新的特征提取网络 提取到的结果， 总是和旧的特征提取网络 提取到的结果有区别。 

思路一 ：所以我们只需要让新的特征网络接近旧的网路，并且还能够完成我们新的要求就好了。即既能在旧的特征起很好作用，又能在新的特征完成检索任务。因此可以设置两部分的损失函数来约束或者引导新的特征提取器的训练，一部分损失函数约束要和之前的网络提取特征对齐，一部分的损失函数要使得网络能够完成新的任务。 

接下来，我们尝试引入一些符号对上述的过程进行表示，

首先，由于是进行机器学习，所以 query 进入检索的图像，并不是只有若干个，而是有一个大数据集，我们将其称之为  **Query Set**  或者 **Query Photo Collection** ， 使用符号 $Q$ 表示。  

然后与之对应的是，被搜索的图像集合 ，这里包含了所有的数据，里面有着若干类。其中有一些数据是能够和输入**Query**进行匹配的，一些数据是无法与 **Query** 进行匹配的。我们将这个称之为 **Gallery Photo Collection** , 使用符号 $D$ 表示。

这里提到了类别，其实图像搜索和分类有些联系，因为我们图像检索的目标是在 Gallery 中找到 与Query 匹配的，这个匹配大家理解还是图像类别的匹配，比如输入我的照片，我是希望得到我的所有照片，而不是我的狗的所有照片。所以其实还是做一个类别匹配，或者是进行分类的操作。另外，图像分类任务的好处是有着具体的类别标签和数据集，很多时候图像分类任务训练得到的 特征提取器是能够拿来做图像检索任务的，所以类别依旧是一个重要的，隐含的标签。

所以可以认为 在这些数据中，Query 和 Gallery 包含了若干个类，











