---
layout: post
title:  Paper Reading 3  Continual Learning in Image Retrieval AI  Summary 
categories: [Paper Reading, Continual Learning ] 
description: 
keywords: [Paper Reading, Continual Learning, Image Retrieval ] 

---



# Paper Reading 3  Continual Learning in Image Retrieval ( AI summary)



这里分享关于 continual learning 在图像搜索 Image Retrieval 任务中的一些研究。

按着我的理解，其大意就是我们手机的相册，现在不都有 AI 分类功能了嘛，会按着人的面孔进行分类，但当有着新的类别，或者同一类别下的不同数据进来，怎么还能在之前的数据和新进来的数据都能够分类地很好，但这个还不是简单的图像分类，并没有一个文本对应的标签。而是类似于以图搜图的功能， 所以这里的标签就不是简单的标注的文本，而是这一类的图像。

给一个搜索的图像，搜索到所有和这个图像相关的图像。 这个任务就是 Image Retrieval. 

首先介绍关于 Image Retrieval 一些基本的概念。

# Image Retrieval

在**图像检索（Image Retrieval）**任务中，主要目标是通过计算查询图像（query image）的特征与数据库中已有图像（gallery images）的特征相似度，检索出与查询图像最相关的图像。以下是图像检索领域的一些基本概念：

### 1. **Query（查询图像）**

**查询图像（Query Image）**是指用户提供的一张图像，系统根据这张图像去检索数据库中最相似的图像。查询图像在图像检索任务中起到“搜索条件”的作用，它的特征会与数据库中其他图像的特征进行比较，从而找到最相似的结果。

- **特征提取**：在进行检索之前，模型首先会从查询图像中提取特征表示（feature embedding）。这些特征通常是通过卷积神经网络（CNN）或预训练模型生成的高维特征向量。
  
- **距离度量**：查询图像的特征表示将与数据库中的所有图像特征进行距离计算，常用的距离度量方式包括欧几里得距离（Euclidean distance）、余弦相似度（Cosine similarity）等。距离越小，图像的相似度越高。

### 2. **Gallery（图库或候选图像集）**

**图库（Gallery）**，也称为**候选图像集**，是指数据库中存储的所有图像，这些图像的特征已被提前索引，待查询图像检索时用于比较和匹配。图库中的图像与查询图像通过计算相似度来确定检索结果。

- **特征库**：在图库中的每张图像，都会有对应的特征向量，这些特征通常是通过特征提取模型生成并提前索引的。当用户输入查询图像时，系统会从这个特征库中检索出最匹配的图像。

- **重新索引问题**：在持续学习或增量学习中，一个主要的挑战是如何在不重新计算或重新索引图库中所有图像特征的情况下，保持检索系统的有效性。

### 3. **Feature Embedding（特征嵌入）**

**特征嵌入（Feature Embedding）**是指将图像转换为高维向量表示，这些向量用于计算图像之间的相似度。每张图像的特征向量通常是在神经网络（例如卷积神经网络）中经过一系列卷积层和池化层提取的。

- **表示空间（Representation Space）**：特征嵌入会将图像映射到一个高维空间，在该空间中，相似的图像的特征向量会距离较近，而不相似的图像则距离较远。

- **学习特征嵌入**：特征嵌入通常通过监督学习或无监督学习的方式获得。在监督学习中，模型通过学习类间区分度较大的特征，使得同类图像特征向量距离更近，而不同类图像特征向量距离更远。

### 4. **Distance Metric（距离度量）**

**距离度量（Distance Metric）**用于衡量查询图像的特征与图库中每张图像的特征之间的相似度。在图像检索中，距离度量是至关重要的，因为它决定了检索结果的排序。常用的距离度量方法包括：

- **欧几里得距离（Euclidean Distance）**：这是计算两个向量之间的直线距离。公式为：
  $$
  d(x, y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}
  $$
  距离越小，图像越相似。

- **余弦相似度（Cosine Similarity）**：用于计算两个向量之间的夹角余弦值，表示相似度。公式为：
  $$
  \text{cos}(x, y) = \frac{x \cdot y}{\|x\| \|y\|}
  $$
  余弦相似度越大，图像越相似。

### 5. **Re-indexing（重新索引）**

**重新索引（Re-indexing）是指在模型更新或新任务引入后，重新计算图库中所有图像的特征表示**。如果模型的特征表示发生了变化，那么为了保证检索的有效性，必须重新计算图库中图像的特征向量。这种操作可能会带来巨大的计算开销，尤其是在大规模数据集上。

- **兼容性问题**：为了避免重新索引问题，一些方法（如 CL2R）试图保持新旧模型特征的兼容性，使得新模型生成的特征仍然与旧模型的特征空间一致，避免了重新索引的需求。

### 6. **Catastrophic Forgetting（灾难性遗忘）**

**灾难性遗忘（Catastrophic Forgetting）**是指当模型学习新任务时，由于新知识的加入，模型可能会遗忘之前学到的知识。在图像检索中，灾难性遗忘表现为模型在学习新类图像后，无法正确处理和检索之前的旧类图像。

- **解决方案**：如 CL2R、Backward Consistent Feature Embedding 等方法，通过特征对齐、特征蒸馏和回放策略等技术，减少新任务引入对旧任务特征表示的破坏，从而避免灾难性遗忘。

### 7. **Compatible Representation（兼容特征表示）**

**兼容特征表示（Compatible Representation）**是指新模型生成的特征与旧模型生成的特征在同一空间中保持一致，使得新旧任务特征可以一起用于检索。这种兼容性避免了模型更新后重新计算旧任务特征的需求。

- **终身兼容性（Lifelong Compatibility）**：在持续学习中，特征表示的兼容性至关重要，尤其是在大规模视觉检索系统中。兼容的特征表示确保系统能够在学习新类的同时保持对旧类的检索能力。

### 总结

在**图像检索**任务中，关键概念如**查询图像（Query Image）**、**图库（Gallery Images）**、**特征嵌入（Feature Embedding）**和**距离度量（Distance Metric）**共同构成了整个检索系统的基础。通过有效的特征提取和距离计算，系统能够根据查询图像在图库中检索到最相似的结果。同时，解决**灾难性遗忘**、**重新索引**和保持**兼容特征表示**是持续学习与增量学习中的重要挑战。

# 图像检索（Image Retrieval）和图像分类（Image Classification）的区别

**图像检索（Image Retrieval）**和**图像分类（Image Classification）**是计算机视觉领域中的两个经典任务，它们有着不同的目标和方法，但在某些方面也存在一定的联系。下面将分别讨论这两个任务的**不同点**和**联系**。

### 1. **图像检索（Image Retrieval）**

**图像检索**的任务是：给定一张**查询图像（Query Image）**，从一个**图库（Gallery）**中检索出与查询图像**最相似的图像**。

- **目标**：图像检索的目标是找到与查询图像最相似的图像，通常通过计算查询图像与图库中所有图像之间的特征相似度来实现。
  
- **过程**：
  1. 提取查询图像和图库中所有图像的特征表示（Feature Embedding），通常是通过卷积神经网络（CNN）等模型来生成高维特征向量。
  2. 使用某种距离度量（如欧几里得距离、余弦相似度等）来衡量查询图像与图库中每张图像的特征向量之间的相似度。
  3. 根据相似度将图库中的图像排序，返回与查询图像最相似的图像。

- **评价指标**：常用的评价指标包括**平均精度（mAP）**、**Top-K准确率**等。

- **应用**：图像检索任务通常应用于**图像搜索引擎**、**内容推荐**、**身份验证（如人脸识别）**等场景。

### 2. **图像分类（Image Classification）**

**图像分类**的任务是：给定一张图像，预测该图像所属的**类别标签**。

- **目标**：图像分类的目标是为输入图像分配一个特定的类别标签，通常是在预定义的类别集合中选取一个标签。

- **过程**：
  1. 提取输入图像的特征表示，通常使用卷积神经网络（CNN）来提取图像的高维特征。
  2. 通过一个分类器（如全连接层+Softmax函数），预测该图像属于某个特定类别。
  3. 模型根据预测的概率分布输出最可能的类别。

- **评价指标**：常用的评价指标包括**分类准确率（Accuracy）**、**混淆矩阵（Confusion Matrix）**、**Precision、Recall、F1 Score**等。

- **应用**：图像分类通常应用于**物体识别**、**垃圾邮件检测**、**医疗影像分析**、**自动驾驶**等领域。

### 3. **图像检索和图像分类的不同点**

- **任务目标**：
  - **图像分类**：目标是为一张输入图像分配一个预定义的类别标签，解决的是**分类问题**。
  - **图像检索**：目标是从图库中找出与查询图像**相似的图像**，解决的是**相似度匹配问题**。

- **结果输出**：
  - **图像分类**：模型输出一个类别标签或一组类别的概率分布。
  - **图像检索**：模型返回一个图像集合，按与查询图像的相似度排序。

- **数据依赖性**：
  - **图像分类**通常要求数据集是**有标签**的，即每张图像都带有明确的类别标签。
  - **图像检索**不一定需要标签，通常只需要图像本身，并通过特征相似性进行匹配。

- **评价标准**：
  - **图像分类**主要以准确率（Accuracy）为评价标准，强调的是类别预测的准确性。
  - **图像检索**主要使用检索精度（mAP）等指标，强调的是检索结果的排序和相关性。

- **计算方式**：
  - **图像分类**需要通过训练学习一个分类器来映射图像到特定的类别。
  - **图像检索**更多依赖于图像的特征表示和距离度量，主要关注如何定义图像之间的相似性。

### 4. **图像检索和图像分类的联系**

尽管图像检索和图像分类是两个不同的任务，它们在一些技术上有较强的联系，特别是在特征表示（Feature Representation）和模型结构上。

- **卷积神经网络（CNN）**：两者都依赖 CNN 提取图像的深度特征。图像分类任务中的分类器通常是在提取的特征基础上训练的，而图像检索任务也需要通过 CNN 提取图像的特征向量。
  
- **特征表示的共享**：在图像分类任务中，最后一层全连接层之前的特征通常是高维的**特征嵌入向量**，这些向量也可以用于图像检索任务。因此，图像分类网络可以通过修改其最后的分类层，直接用于图像检索任务。

- **端到端学习**：两者都可以通过端到端训练的方式来优化特征表示。对于图像检索任务，常常在训练过程中加入三元组损失（Triplet Loss）或对比损失（Contrastive Loss）等，使得同类图像特征之间更接近，而不同类图像特征更分散。

- **相同的数据预处理和网络结构**：两者通常使用相同的图像预处理技术（如归一化、数据增强等）和相似的网络架构（如 ResNet、VGG、Inception 等）进行特征提取和学习。

### 5. **总结**

- **不同点**：图像分类的目标是预测输入图像的类别标签，而图像检索的目标是基于图像相似度从图库中找到最相似的图像。两者的任务不同，输出和评价标准也不同。
  
- **联系**：两者在图像特征表示上有很强的联系，都依赖于 CNN 提取高维特征向量。图像分类模型提取的特征可以直接用于图像检索任务。两者可以通过端到端的方式共同优化特征表示，提升分类和检索的效果。

在实际应用中，图像分类和图像检索的组合常常用于构建高效的图像识别和检索系统。例如，一个系统可以首先通过图像分类确定图像的类别，然后在该类别中进行图像检索，从而提高系统的整体性能。



# 为什么 图像检索任务也会有特征提取器和分类器

在图像检索的相关论文中，虽然图像检索的核心任务是通过特征相似度找到与查询图像相似的图像，而**不需要直接使用分类器**，但特征提取器和分类器的概念仍然会频繁出现，这是因为：

### 1. **特征提取器与分类器的共享基础**
图像检索和图像分类在**特征表示**的学习上有很大的相似性。无论是图像分类还是图像检索，**特征提取器（Feature Extractor）** 都是核心组件，它从图像中提取有用的特征表示。大多数现代图像分类和检索系统使用卷积神经网络（CNN）等深度学习模型来学习图像的高维特征表示。特征提取器的任务是在训练阶段提取图像的深层次信息，使得图像可以通过特征向量在高维空间中表示。

- **图像分类**：通过特征提取器提取特征，之后通过**分类器**将图像的特征向量映射到预定义的类别标签。
  
- **图像检索**：通过特征提取器提取特征，但不用映射到具体类别，而是用这些特征向量计算相似度，进而进行检索。

因此，虽然图像检索的最终目标不是分类，但**特征提取器的设计和训练**常常是借助于分类任务完成的，特征提取器和分类器的概念共享同一套基础模型。训练分类器有助于学习更好的图像特征，这些特征同样可以用于图像检索。

### 2. **使用图像分类来学习有效的特征嵌入**
大多数图像检索模型都是基于**深度特征嵌入**的方式来表示图像。这些嵌入通常是通过**分类任务**训练的模型获得的。在图像分类任务中，网络会通过卷积层学习到表示图像的特征，这些特征用于区分不同类别。通过训练网络进行分类任务，模型学到的特征嵌入不仅有很强的区分能力，也在图像检索中能有效表示图像的相似度。

- **分类器帮助训练特征提取器**：在分类任务中，分类器的作用是引导网络学习到对类别区分有用的特征。在训练过程中，模型的卷积层（即特征提取器）提取的特征被送到分类器进行最终分类，这样模型会学习到能够区分不同类别的特征表示。这种学习方式也可以帮助图像检索系统获得有区分度的特征。

- **提取到的特征可以用于检索**：分类任务训练得到的特征嵌入表示（特征向量）可以直接应用于图像检索，通过比较图像的特征向量相似度来进行检索，而不需要再次训练特征提取器。

### 3. **深度学习模型的端到端训练**
在现代深度学习中，分类器和特征提取器通常是一体化训练的。即使最终目标是图像检索，模型仍然可能通过**分类任务进行预训练**，然后将分类层去除，直接使用特征提取器来输出特征嵌入。

例如，ResNet、VGG、Inception 等卷积神经网络模型在图像分类任务中非常流行。这些模型的卷积层和全连接层共同构成特征提取器和分类器。在许多图像检索的研究中，研究者会首先使用图像分类任务对这些模型进行预训练（利用标注好的数据集），从而学习到良好的特征表示。然后在检索任务中，研究者可以移除模型的分类器部分，只使用其卷积层（特征提取器）来提取图像特征并进行检索。

### 4. **基于分类任务优化特征学习**
为了让图像检索系统学习到有用的特征表示，研究者通常使用基于分类任务的损失函数（如交叉熵损失）来优化特征提取器。这种优化方式能够让模型学习到**区分度更高的特征**，从而在图像检索中表现更好。

此外，研究者还会使用一些特殊的损失函数来增强特征提取器的效果，常见的有：
- **三元组损失（Triplet Loss）**：通过最小化同类样本之间的特征距离，并最大化不同类样本之间的特征距离，增强模型的检索能力。
- **对比损失（Contrastive Loss）**：用于训练模型使得同类图像特征靠近，不同类图像特征远离。

这些损失函数在训练时可能结合分类器进行优化，帮助模型学习到更具有区分性的特征表示。

### 5. **BCT 方法中的分类器和特征提取器**
在**Backward-Compatible Training (BCT)** 方法中，**分类器**仍然是非常重要的一部分。虽然 BCT 主要用于解决**向后兼容性**问题，以确保新模型的特征表示能够兼容旧模型的特征，但它的训练过程依然涉及分类任务：
- **特征提取器**：用于提取图像的深度特征，形成高维特征嵌入。
- **旧模型分类器的约束**：BCT 通过在新模型训练时，利用旧模型的分类器来约束新模型的特征提取器，使新模型生成的特征仍然能够被旧分类器正确分类。这样，新模型的特征和旧模型特征保持兼容性，避免重新索引旧特征。

### 总结

虽然**图像检索**的核心任务是通过特征相似度来匹配图像，而不需要使用分类器，但特征提取器和分类器之间的联系非常紧密：
1. **特征提取器和分类器在训练过程中相辅相成**：分类器帮助特征提取器学习到更有效的图像特征，特征提取器则为分类器提供了图像的高维表示。
2. **图像检索任务中可以利用分类任务预训练的特征**：很多图像检索模型的特征提取器是在分类任务中训练好的，这种方法可以帮助学习到具有强区分能力的特征表示。
3. **在一些图像检索相关的论文中，分类器起到了优化特征提取器的作用**，例如 BCT 方法利用旧分类器约束新模型特征提取器，从而保持特征兼容性。

因此，即使图像检索的任务不直接需要分类器，分类器的概念在训练阶段和特征学习过程中仍然起到了关键作用。





# MMD--On the Exploration of Incremental Learning  for Fine-grained Image Retrieval

## 论文信息

On the Exploration of Incremental Learning  for Fine-grained Image Retrieval



## 设定

本文研究了在增量设置下，细粒度图像检索（Fine-grained Image Retrieval, FGIR）的问题。当新类别随着时间的推移不断加入时，如何在不访问原始类别样本的情况下进行有效的增量学习，同时防止遗忘原有类别的知识。 

在现实应用中，图像数据和类别的数量不断增加。传统的图像检索方法通常基于静态数据集，无法适应不断增加的新类别。当模型对所有类别进行联合训练时，可以保证性能，但这种重复训练过程非常耗时。另一方面，仅对新类别进行微调会导致“灾难性遗忘”问题，即模型会忘记对原始类别的良好性能。因此，本文提出了一种增量学习方法，以缓解由于遗忘问题导致的检索性能下降。

## 创新点

本文的创新点在于提出了一种适用于细粒度图像检索（FGIR）的增量学习框架，能够有效应对新类别的逐步加入，同时防止“灾难性遗忘”原始类别。具体来说，创新点包括：

1. **无样本增量学习**: 本文的方法在学习新类别时不访问任何原始类别的样本，这解决了由于隐私问题或存储限制而无法访问原始数据的现实问题。
2. **知识蒸馏结合最大均值差异（MMD）**: 提出了基于知识蒸馏和MMD的双重正则化策略，知识蒸馏用于保持分类器输出的一致性，MMD用于最小化特征分布差异，从而在增量学习过程中保持良好的检索性能。
3. **细粒度图像检索的增量学习**: 该方法首次将增量学习应用于细粒度图像检索，展示了其在处理细微类别差异方面的优势。

![image-20241022140612201](https://zuti.oss-cn-qingdao.aliyuncs.com/img/202410221406300.png)

## 方法设计思想

该方法的设计思想是通过联合使用知识蒸馏和MMD正则化，来同时实现对新类别的适应能力和对原始类别的记忆保留。具体来说：

- **知识蒸馏**: 将原始网络的软标签作为监督信号，用于训练新的适应性网络，确保新网络在增量训练过程中不会过多地偏离原始网络的决策边界。
- **MMD正则化**: MMD用于在特征空间中度量原始网络和新网络之间的分布差异，最小化该差异能够保持新网络与原始网络在特征表示上的一致性，从而缓解遗忘问题。

## 原理与技术细节

###  Semantic Preserving Loss

Semantic Preserving Loss 通过交叉熵损失和三元组损失来捕捉类别间的语义特征，确保新旧类别之间的特征保持一致，从而减少遗忘效应。

#### 交叉熵损失

交叉熵损失（Cross-Entropy Loss）用于分类任务，通过最小化预测值与真实标签之间的距离来训练模型。假设模型的输出 logits 为 $(o_1, o_2, \dots, o_n)$，真实的类别标签为 $(y_1, y_2, \dots, y_n)$，则交叉熵损失公式如下：


$$
L_{ce} = -\frac{1}{N} \sum_{i=1}^{N} \left( y_i \cdot \log \left( \frac{e^{o'_i(x)}}{\sum_{j=n+1}^{n+m} e^{o'_j(x)}} \right) \right)
$$


其中，$N$ 是样本数，$y_i$ 是第 $i$ 个样本的标签，$o'_i(x)$ 是该样本通过网络后的预测值的 logits，$n+m$ 表示新旧类别的总数。

log 后面的是一个softmax 函数. Softmax 函数的主要作用是将模型输出的 logits 转换成可以理解为概率的数值，这些概率反映了样本属于不同类别的可能性。Softmax 的公式如下：


$$
p_i = \frac{e^{o_i}}{\sum_{j=1}^{n+m} e^{o_j}}
$$


其中：

- $p_i$ 是第 $i$ 类的预测概率；
- $o_i$ 是模型在第 $i$ 类上的输出（logit 值）；
- $n+m$ 是类别的总数（$n$为原始类别数，$m$为新增类别数）。

Softmax 通过计算各类 logit 值的指数并对它们求和来进行归一化处理，保证输出的概率总和为 1

注意由于增量学习中的数据访问限制设定，无法得到之前的数据，因此这里仅使用新的类别的图像的数据。这个也就是要求 新类别的数据能够被正常分类。



#### 三元组损失

为了更好地区分细粒度类别，采用了三元组损失（Triplet Loss）。三元组损失提高了特征向量的判别性。

三元组损失通过“难正样本对”（hard positive pairs）和“难负样本对”（hard negative pairs）来优化模型，使得相同类别的样本之间距离更近，不同类别的样本之间距离更远。其公式如下：


$$
L_{triplet} = \frac{1}{N} \sum_{i=1}^{N} \max \left( 0, \lambda + S_{i, \text{neg}} - S_{i, \text{pos}} \right)
$$


其中，$S_{i, \text{neg}}$ 表示第 $i$ 个样本与难负样本之间的相似度，$S_{i, \text{pos}}$ 表示该样本与难正样本之间的相似度，$\lambda$ 是用于区分正负样本的边界阈值。 



### 知识蒸馏损失（Distillation Loss）

**原理**: 知识蒸馏旨在将原始网络（教师网络）中的知识转移到新的适应性网络（学生网络），通过**使得学生网络的输出与教师网络的输出接近**，从而保持对原始类别的识别能力。

**技术细节**:

- 定义原始网络的输出 logits 为 $(o_1, o_2, \ldots, o_n)$，适应性网络的输出为 $(o'_1, o'_2, \ldots, o'_n, o'_{n+1}, \ldots, o'_{n+m})$。

- 蒸馏损失定义为：

  

$$
\begin{aligned}
L_{\text{dist}} = -\frac{1}{|X_{c'}|} \sum_{x \in X_{c'}} \sum_{k=1}^{n} \left\{ p_k(x) \cdot \log p'_k(x)] \right\}
\\
p_k(x) = \frac{e^{o_k(x) / T}}{\sum_{j=1}^{n} e^{o_j(x) / T}}, \quad


p'_k(x) = \frac{e^{o'_k(x) / T}}{\sum_{j=1}^{n} e^{o'_j(x) / T}} \\

\end{aligned}
$$

$T$ 为温度参数，通常设为2。



### 最大均值差异损失（MMD Loss）

**原理**: 目的是减少新模型与原模型在特征分布上的差异。MMD用于衡量两个特征分布之间的距离，通过最小化新网络与冻结网络（即原始网络）特征分布的MMD，保了新模型的特征分布尽可能与原模型的特征分布相近，从而保留原模型的特征信息。

**技术细节**:

给定来自原始网络和新网络的特征向量集合 $R$ 和 $R'$，MMD计算特征分布均值之间的距离：


$$
\text{MMD}^2(R, R') = \left\| \frac{1}{N} \sum_{i=1}^{N} \phi(R_i) - \frac{1}{N} \sum_{j=1}^{N} \phi(R'_j) \right\|^2_{\mathcal{H}}
$$



其中，$R$ 和 $R'$ 是两组样本的特征， $\phi(\cdot)$ 是将特征映射到再生核希尔伯特空间（RKHS）的函数， $\mathcal{H}$ 表示再生核希尔伯特空间（RKHS）。这里 $\phi$ 函数的作用是将原始的特征映射到一个高维的特征空间，在这个空间中进行均值计算和距离度量。

通过将平方展开并结合希尔伯特空间的性质，得到


$$
\begin{aligned}
MMD^2(R, R') = \frac{1}{N^2} \left( \sum_{i=1}^{N} \sum_{j=1}^{N} \langle \phi(R_i), \phi(R_j) \rangle_{\mathcal{H}} + \sum_{i=1}^{N} \sum_{j=1}^{N} \langle \phi(R'_i), \phi(R'_j) \rangle_{\mathcal{H}} - 2 \sum_{i=1}^{N} \sum_{j=1}^{N} \langle \phi(R_i), \phi(R'_j) \rangle_{\mathcal{H}} \right)
\end{aligned}
$$


在这个公式中，$\langle \phi(R_i), \phi(R_j) \rangle_{\mathcal{H}}$ 表示 $R_i$ 和 $R_j$ 在高维空间 $\mathcal{H}$ 中的内积。

为了简化计算，使用核技巧替代内积。 在实际操作中，直接计算 $\phi(R_i)$ 通常非常困难，因为 $\phi(\cdot)$ 通常是一个高维甚至无限维的映射。因此，无法直接在 $\mathcal{H}$ 中进行内积和距离计算。 **核技巧**的核心思想是，虽然我们无法明确计算出 $\phi(R_i)$，但我们可以通过核函数 $k(R_i, R_j)$ 间接计算出 $\phi(R_i)$ 和 $\phi(R_j)$ 在高维空间中的内积：


$$
k(R_i, R_j) = \langle \phi(R_i), \phi(R_j) \rangle
$$


将核函数 $k$ 代入上面的公式后，MMD 损失可以表示为：


$$
MMD^2(R, R') = \frac{1}{N^2} \left( \sum_{i=1}^{N} \sum_{j=1}^{N} k(R_i, R_j) + \sum_{i=1}^{N} \sum_{j=1}^{N} k(R'_i, R'_j) - 2 \sum_{i=1}^{N} \sum_{j=1}^{N} k(R_i, R'_j) \right)
$$


在论文中，作者采用了**高斯核（Gaussian kernel）**，其形式为：


$$
k(R_i, R_j) = \exp \left( -\frac{\| R_i - R_j \|^2}{2 \sigma^2} \right)
$$


其中：

- $| R_i - R_j |^2$ 表示 $R_i$ 和 $R_j$ 之间的欧氏距离；
- $\sigma$ 是高斯核的参数，用来控制核函数的尺度。





最终得到 MMD 损失为：


$$
L_{\text{mmd}} = \text{MMD}(R, R') = \sqrt{\frac{1}{N} \left[\sum_{i=1}^{N} \sum_{j=1}^{N} k(R_i, R_j) - 2 \sum_{i=1}^{N} \sum_{j=1}^{N} k(R_i, R'_j) + \sum_{i=1}^{N} \sum_{j=1}^{N} k(R'_i, R'_j) \right]}
$$



其中，$k(R_i, R_j)$ 是核函数，它的输出是 $\phi(R_i)$ 和 $\phi(R_j)$ 在高维空间中的内积值，而不需要显式地计算 $\phi(R_i)$ 和 $\phi(R_j)$。$k(R, R') = \exp\left(-\frac{\|R - R'\|^2}{2\sigma^2_m}\right)$，$\sigma_m$ 是高斯核中的方差。

### 总体损失函数

综合考虑多个损失函数，构建一个整体目标函数，以平衡新旧类别之间的性能。

**技术细节**:

最终的目标函数为：



$$
L = \alpha L_{\text{dist}} + \beta L_{\text{mmd}} + (L_{\text{ce}} + L_{\text{triplet}})
$$



其中，$\alpha$ 和 $\beta$ 是权衡参数，

$L_{\text{ce}}$ 为交叉熵损失，$L_{\text{triplet}}$ 为三元组损失， 描述了新添加的样本的正确识别和分类效果。**交叉熵损失** 和 **三元组损失** 则用于训练模型识别新类别，并提升其在新类别上的性能。

$L_{\text{dist}}$ 是为了将新旧模型的输出进行对齐， $L_{\text{mmd}}$ 是为了将新旧模型的特征空间进行对齐，负责保持对原有类别的知识和特征分布，防止模型在学习新类别时遗忘旧类别。

$\alpha L_{\text{dist}} + \beta L_{\text{mmd}}$ 描述了将新旧模型进行对齐的设置，分别是输出和特征两方面进行对齐，此外还设置了参数来权衡这两方面的重要性

## 思考与疑问

这里使用MMD Loss 来进行衡量新模型与原模型在特征分布上的差异，这是基于最终输出分布结果的差异进行衡量的，那使用其他类似的方法。这里提到的**特征之间的差异**，通常是指**同一个输入样本在新模型和旧模型中的特征向量需要尽可能一致**。也就是说，对于同一个输入数据（例如一张图片或一个文本），新模型所提取的特征表示（特征向量）应该与旧模型提取的特征表示尽量相似，以保持特征空间的**一致性**。通过让同一个输入样本的特征向量在新旧模型中保持一致，可以有效避免增量学习中的灾难性遗忘，并确保新旧模型在同一特征空间中工作，从而保持向后兼容性。

除了 **MMD Loss（Maximum Mean Discrepancy Loss）** 用于衡量新模型与原模型在特征分布上的差异外，以下是几种常用的其他方法，它们在增量学习和特征对齐问题中广泛使用，可以有效地衡量新旧模型的特征分布差异：

### 1. **知识蒸馏（Knowledge Distillation）**
知识蒸馏是衡量新旧模型特征分布差异的经典方法。最初由 Hinton 等人提出，用于将大模型的知识提取到小模型中。增量学习中的知识蒸馏是通过保持新模型与旧模型在相同输入下的输出相似来防止灾难性遗忘。

#### 公式：


$$
L_{KD} = \sum_{i} \text{KL}(p_{old}(x_i) || p_{new}(x_i))
$$
其中：
- $p_{old}(x_i)$ 是旧模型对于输入 $x_i$ 的输出概率分布；
- $p_{new}(x_i)$ 是新模型的输出概率分布；
- $\text{KL}(\cdot)$ 是 KL 散度，用于衡量两个概率分布之间的差异。

#### 优点：
- **简单高效**：不需要额外的复杂计算，直接使用新旧模型的输出进行对齐；
- **广泛应用**：知识蒸馏在各种增量学习场景中都非常有效，特别是在保持新旧模型的特征一致性方面。

#### 缺点：
- **对概率输出敏感**：蒸馏过程中对于输出的精确匹配可能不总是最佳的，尤其是当特征表示空间较为复杂时。

### 2. **对抗性特征对齐（Adversarial Feature Alignment）**
对抗性学习是另一种用于对齐新旧模型特征分布的常用方法。通过引入一个对抗性网络来判断特征是来自新模型还是旧模型，从而引导新模型的特征分布向旧模型的特征分布靠近。

#### 主要机制：
- 训练一个判别器，区分特征是否来自旧模型；
- 通过对抗性损失，优化新模型使得其生成的特征不能被判别器区分，从而实现特征对齐。

#### 对抗性损失函数：


$$
L_{adv} = - \frac{1}{N} \sum_{i=1}^{N} \log D(f_{new}(x_i)) + \log(1 - D(f_{old}(x_i)))
$$


其中：

- $D(\cdot)$ 是判别器；
- $f_{new}(x_i)$ 和 $f_{old}(x_i)$ 分别是新模型和旧模型的特征表示。

#### 优点：
- **强大的特征对齐能力**：对抗性机制能够在复杂分布中有效对齐特征分布；
- **灵活性**：可以应用在多种不同类型的任务中（如分类、检索等）。

#### 缺点：
- **训练复杂**：需要训练额外的判别器，并且容易导致训练不稳定（如模式崩溃等）。

### 3. **基于特征重放的增量学习（Feature Replay）**
特征重放是一种类似经验重放的技术，但不同之处在于它重放的是旧模型生成的特征，而不是直接重放原始数据。这种方法通过保留一些旧模型的特征，强制新模型的特征与旧特征保持一致。

#### 机制：
- 保留一些旧任务的数据或特征；
- 在训练新任务时，将这些旧任务的特征作为约束，让新模型尽量保持旧任务的特征一致性。

#### 公式：


$$
L_{replay} = \frac{1}{N} \sum_{i=1}^{N} \left\| f_{new}(x_i) - f_{old}(x_i) \right\|^2
$$

#### 优点：
- **减少灾难性遗忘**：特征重放能够显著减少新任务对旧任务知识的破坏；
- **数据效率高**：相比直接重放原始数据，特征重放的存储和计算开销较小。

#### 缺点：
- **特征选择依赖性**：需要选择适当的特征来重放，特征选择不当可能影响模型的效果。

### 4. **投影对齐（Projection Matching）**
投影对齐是一种直接通过投影矩阵将新旧特征进行对齐的方法。假设新模型和旧模型在不同的特征空间中工作，投影对齐通过一个投影矩阵将新模型的特征空间映射到旧模型的特征空间中，从而保持特征一致性。

#### 公式：
$$
L_{proj} = \frac{1}{N} \sum_{i=1}^{N} \left\| P f_{new}(x_i) - f_{old}(x_i) \right\|^2
$$
其中 $P$ 是一个投影矩阵，将新模型的特征映射到旧模型的特征空间中。

#### 优点：
- **显式对齐**：通过投影的方式可以显式地对齐特征空间，较为直观；
- **灵活应用**：可以在不同的特征空间之间进行转换。

#### 缺点：
- **可能会丢失信息**：如果投影矩阵的设计不合理，可能会丢失部分新模型的特征信息。

### 5. **基于层级的特征对齐（Layer-wise Feature Alignment）**
在深度神经网络中，不同层次的特征可能有不同的分布。层级特征对齐通过逐层比较新旧模型相应层的特征分布，并使用损失函数将每一层的特征对齐，确保模型从低层到高层的特征都保持一致。

#### 公式：
$$
L_{layer} = \sum_{l=1}^{L} \left\| f_{new}^l(x_i) - f_{old}^l(x_i) \right\|^2
$$
其中，$f_{new}^l(x_i)$ 和 $f_{old}^l(x_i)$ 分别是新模型和旧模型在第 $l$ 层提取的特征。

#### 优点：
- **精细控制**：可以在网络的不同层次精确控制特征对齐，提供更强的约束。
  
#### 缺点：
- **计算复杂**：需要计算多层的特征对齐，训练时计算量较大。

### 总结

除了 **MMD Loss**，知识蒸馏、对抗性特征对齐、特征重放、投影对齐和层级特征对齐等方法都是常用的衡量新旧模型特征分布差异的手段。这些方法各自有其优点和适用场景，可以根据具体任务需求和模型架构进行选择。

**不同方法的权衡**：
- 如果需要简单且高效的特征对齐，知识蒸馏是常用且稳健的选择；
- 如果特征分布较为复杂且需要强力对齐，对抗性特征对齐和 MMD Loss 是不错的选择；
- 特征重放适合于存储空间有限且希望减少灾难性遗忘的场景；
- 投影对齐和层级对齐适用于需要对不同特征空间进行显式处理的情况。





# BCT--Towards Backward-Compatible Representation Learning

## 1. Scope or Setting（研究背景与问题设定）

本论文探讨了在开放世界的视觉分类和检索任务中，如何通过训练新模型，使得新旧模型的特征表示保持**向后兼容性（Backward Compatibility）**，从而避免重新计算旧模型的特征表示。作者提出了一种名为**Backward-Compatible Training (BCT)** 的训练方法，旨在解决这一问题。

###  Key Idea（核心思想）

论文的核心思想是通过向后兼容训练，使得新模型生成的特征表示可以直接与旧模型的特征表示进行对比，而无需重新索引旧的特征表示。这种方法通过在新模型的训练中引入**影响损失（Influence Loss）**，使新模型的特征表示与旧模型保持一致。

![image-20241023180412203](https://zuti.oss-cn-qingdao.aliyuncs.com/img/202410231804528.png)

这一张图就能把BCT的想法解释地特别清晰，

最大的区别在于上面的第一张图需要把整个 Gallery 的图像重新放大新的模型，得到在新的特征空间下对应的特征向量，生成新的特征数据集。而下面的第二章图，也就是本文中提到的方法就不需要进行这一步，也就是所谓的 Backfilling 或者称之为 Re-indexing。

那是如何进行实现的呢？ 这里面多了一个紫色的箭头，从old model 指向 new model ，也就是 new model 要学会旧模型的特征表示，也就是这里的 backward compatible representation。



## 评判标准 Criterion for Backward Compatibility

在2.2.2节中，文中给出了判断新模型与旧模型在特征空间中是否**向后兼容**的标准，主要通过以下几个不等式进行约束。这些不等式的目的是确保新模型在处理特征表示时，能够像旧模型一样有效地区分不同类别的图像，并且可以将同一类别的图像聚集在一起。

#### 不等式1：区分类别间图像

$$
d(\phi_{\text{new}}(x_i), \phi_{\text{old}}(x_j)) \geq d(\phi_{\text{old}}(x_i), \phi_{\text{old}}(x_j)), \quad \forall (i, j) \in \{(i, j) | y_i \neq y_j \}
$$

- **解释**：这条不等式的意思是，对于属于不同类别的样本 $x_i$ 和 $x_j$，新模型生成的特征表示 $\phi_{\text{new}}(x_i)$ 和 $\phi_{\text{new}}(x_j)$ 之间的距离应该不小于旧模型生成的特征表示之间的距离。这确保了新模型能够至少和旧模型一样好地分离不同类别的图像特征。

- **意图**：该约束的目的是防止新模型对不同类别图像的区分能力下降，即保证新模型能够有效地区分不同类别的特征。

#### 不等式2：聚合同类别图像

$$
d(\phi_{\text{new}}(x_i), \phi_{\text{old}}(x_j)) \leq d(\phi_{\text{old}}(x_i), \phi_{\text{old}}(x_j)), \quad \forall (i, j) \in \{(i, j) | y_i = y_j \}
$$

- **解释**：对于同一类别的样本 $x_i$ 和 $x_j$，新模型生成的特征表示 $\phi_{\text{new}}(x_i)$ 和 $\phi_{\text{new}}(x_j)$ 之间的距离应小于或等于旧模型生成的特征表示之间的距离。这意味着新模型在同类图像的特征聚合方面不应劣于旧模型。

- **意图**：该约束的目的是保证新模型对同类图像的特征聚类能力不会比旧模型差，以确保新模型生成的特征依然能够聚集同类别图像的表示。

### 这些不等式的总意图

这两个不等式共同构成了衡量向后兼容性的标准。简而言之，新模型的特征表示必须能够和旧模型一样好，甚至更好地：
1. **区分**不同类别的图像；
2. **聚集**同一类别的图像。

这些约束使得新模型即使在特征提取维度、网络结构或训练数据集发生变化的情况下，仍然能够与旧模型保持特征兼容性，避免了重新计算旧特征的需求 .

### Method（方法）

论文提出了一种新颖的训练框架，包含以下几个步骤：

- **向后兼容训练（Backward Compatible Training, BCT）**：通过在新模型的训练损失中加入旧模型分类器的影响损失，使得新模型在保持分类准确率的同时，与旧模型的特征表示兼容。
- **损失函数设计**：论文提出了一个包含两个部分的损失函数：一个用于新数据集的常规训练损失，另一个是旧模型分类器的影响损失，公式为： 

$$
L_{BCT}(w_c, w_\phi; T_{new}, T_{BCT})
= L(w_c, w_\phi; T_{new}) + \lambda L(w_c^{old}, w_\phi; T_{BCT})
$$



##  Contribution（创新与贡献）

论文的贡献主要体现在以下几个方面：

1. **定义并解决了向后兼容表示学习问题**，该问题要求新模型在不牺牲准确率的前提下，能够直接与旧模型的特征表示兼容。
2. **提出了向后兼容训练框架（BCT）**，通过影响损失来保持新旧模型特征表示的一致性。
3. **进行了广泛的实验验证**，展示了BCT方法在面部识别等任务中的有效性，并表明该方法可以在多种神经网络架构和损失函数下实现兼容性。

![image-20241023180738238](https://zuti.oss-cn-qingdao.aliyuncs.com/img/202410231807563.png)

### Difference and Innovation（区别与创新）

与传统的方法不同，BCT方法允许在引入新数据或新模型时，不需要重新计算旧特征，从而节省了大量的计算资源。相比于其它增量学习和持续学习方法，BCT强调的是**新旧模型特征表示之间的直接兼容性**，而不是通过知识蒸馏或回放策略来保持旧任务的记忆。





# Continual Learning for Visual Search with Backward Consistent Feature Embedding

## 论文信息

Continual Learning for Visual Search with Backward Consistent Feature Embedding

## 设定

这篇论文的研究设定围绕**视觉搜索中的持续学习**（Continual Learning in Visual Search），主要针对不断增长的图库数据集和分类类别，提出了一种能够**增量学习**的框架。在视觉搜索中，系统需要在每次会话（session）中不断更新数据库，并引入新的类别，这种情况下，模型不仅要学习新类别，还需要**保持旧类别特征嵌入的一致性**，以避免“灾难性遗忘”（Catastrophic Forgetting）和**特征空间不兼容**的问题。

该设定的一个重要特点是，系统在处理每个新会话的数据时，不仅要更新新数据，还需要确保原有数据在检索系统中的表现不下降。这与传统方法不同，传统方法通常需要重新提取旧数据的特征，计算开销非常大，而本文提出的框架通过维持**向后兼容性**（Backward Compatibility）来避免这一问题。

### 创新点（Innovation）

1. **向后兼容的特征嵌入**： 本文最大的创新在于提出了**向后兼容的特征嵌入机制**，该机制允许新旧特征嵌入空间在视觉搜索任务中保持兼容。这意味着在模型更新之后，旧的特征不需要重新提取，模型依然能够有效地使用原来的特征进行检索，从而显著减少了计算开销。与其他方法不同，该方法在保持旧数据表现稳定的同时，能够处理新数据的学习。
2. **通用增量学习设定（General Incremental Setup）**： 本文提出的框架能够处理更加通用的增量学习场景，不仅涵盖了传统的“分离设定”（Disjoint Setup）和“模糊设定”（Blurry Setup），还能够应对新旧类别同时出现的情况。与传统方法不同，**本文不需要预先知道未来所有类别，而是允许模型灵活处理新类别的加入。**
3. **多会话损失函数设计**： 作者设计了三个主要损失函数来确保模型的向后兼容性和新类别的学习能力：
   - **会话内区分损失（Intra-session Discrimination Loss）**：确保新数据在当前会话中的区分能力，用于学习当前session数据的判别性表示，确保模型能够有效区分新数据的类别；
   - **邻近会话模型一致性损失（Neighbor-session Model Coherence Loss）**：通过知识蒸馏，保持新旧模型特征空间的一致性，，避免因新模型引入而导致旧特征失效。
   - **会话间数据一致性损失（Inter-session Data Coherence Loss）**：通过重放旧数据的特征，确保新模型与旧模型在长时间内的一致性。避免因多次更新而造成的特征空间不兼容问题。
4. **避免特征重新提取的机制**： 该方法主要针对视觉搜索中的**特征一致性**，**重点在于如何减少新旧数据在嵌入空间中的不兼容问题**，避免特征重提取带来的计算开销。本文提出了一种避免特征重新提取的机制，确保模型更新后仍然可以使用旧特征空间进行检索。这种机制不仅减少了计算量，还提高了系统在处理大规模图库时的效率，适合实际中的视觉搜索系统。







![image-20241022161459559](https://zuti.oss-cn-qingdao.aliyuncs.com/img/202410221615759.png)



## 原理与技术细节

![image-20241022162512793](https://zuti.oss-cn-qingdao.aliyuncs.com/img/202410221625974.png)

### session间数据一致性损失（Inter-Session Data Coherence Loss）

**设计思想与原理：**  session间数据一致性损失的目的是在多个session之间保持特征空间的一致性，以避免在增量学习过程中，由于特征空间变化而导致的兼容性问题。通过重放嵌入（replayed embedding）和使用少量回放数据，该损失能够确保新学习的特征与先前的嵌入空间保持兼容性。

**技术细节：**  

旧类的特征被提取为 $g_i = f_i\{G_i\} |^j_{i=1}$

目标是在当前的session $j+1$ ，训练模型$f_{j+1}$从$G_{j+1}(\mathbf{g}_{j+1}=f_{j+1}\{G_{j+1}\})$ 中提取特征，且保持之前的特征$\mathbf{g}_{1:j}$保持不变

但由于不同的特征空间不一定具有可比性，为了避免单个session过拟合，将之前所有sessions的特征进行聚合起来，如下式所示


$$
E_c = \frac{1}{j} \sum_{i=1}^j \xi(\mathbf{g}_{ic}),c \in C(i)
$$


其中 ，$C(i)$是在session $i$中出现的类别指数集，即不同的图像类别，例如猫狗可能在不同的 session都会新添加进来 

$\mathbf{g}_{ic}$是 在类别$c \in G_i$中的数据的提取的特征集合， 也就是不同session，相同类别的特征

$\xi$表示 期望运算符

**整个算式大概是说在不同的session $i\in 1,\dots,j$ ，将相同类别$c$的特征放在一起，然后取平均得到这个类的特征均值**



第一部分损失函数为$L^{d_I}_{ \{1:j\};j+1} $， 目的是使得强制session间数据一致性，



$$
L^{d_I}_{ \{1:j\};j+1} = \sum_{c \in \Pi_{j+1}} \sum_{x_i \in c} \|f_{j+1}(x_i) - E_c\|_2^2,
$$



其中 ，

$\Pi_{j+1} = \cup_{i=1}^j C(i) \cap C(j+1)$ 表示当前session $j+1$ 与所有先前session$i\in1,\dots,j$之间的重叠出现的类$c$, 

$x_i$表示当前session $(j+1)$ 中属于类别$c$的数据

**整体大概是说 在第 $j+1$的session 中属于类$c$ 的样本$x_i$ ,它的特征提取结果$f_{j+1}$ 要与 这个类的特征均值 $E_c$ 的差别  **

也就是同一类别在不同session 下要保持特征一致性

第二部分损失函数为 $L^d_{\{1:j\};j+1}$， 目的也是使得不同 session 之间特征变化不要太大。只不过上面全部是基于在特征集合$E_c$下讨论的，下面的公式是考虑在 replay data中的原始数据 data 



$$
L^{d_o}_{{\{1:j\};j+1}} = \sum_{c \in \Gamma_{j+1}} \sum_{\tilde{x}_i \in c} \|f_{j+1}(\tilde{x}_i) - E_c\|_2^2,
$$



其中，

$\Gamma_{j+1} = \cup_{i=1}^j C_{i}$  代表 在旧类$C_i$在 replayed 的数据 ，这里还说使用 iCARL中的技术，在每一类的均值周围搜索邻居，作为代表数据 添加到 replay使用

$\bar{x_i}$ 表示  replay data 中的数据

整体大概是说，当新的session $j+1$ 可能不包含某个特定类$c$，但更新完之后的神经网络$f_{j+1}$ ,依然要保证这个类$c$的特征 和 这个类的特征均值保持一致，那么怎么来做呢，就是从 replay data 中来找到这个类$c$，让它来限制这个新训练后的神经网络，仍然能够保证这个类$c$的结果不变。

综上这两个方法，就得了一个综合总的损失函数，损失函数形式为：


$$
L^d_{\{1:j\};j+1} = \frac{1}{n} \left( L^{d_I}_{{\{1:j\};j+1}} + L^{d_o}_{{\{1:j\};j+1}} \right)
$$



- 使用“重放嵌入”策略，即保留每个session中的一部分嵌入，并在后续session中使用这些嵌入进行训练，以保持特征空间的一致性。

- 损失函数考虑了当前session与所有先前session之间的特征空间一致性。

###  相邻session模型一致性损失（Neighbor-Session Model Coherence Loss）

**设计思想与原理：**  

相邻session模型一致性损失旨在通过知识蒸馏的方式保持相邻session模型之间的特征空间一致性。该损失函数通过使得当前session模型的输出与前一session模型的输出一致，来防止模型在更新过程中遗忘之前学到的特征表示。通过这种方式，模型能够在增量学习的同时，保持对旧数据的良好表现。

**技术细节：**  

- 使用一种基于三元组（triplet loss）的蒸馏策略，将之前session模型（教师模型）生成的嵌入作为指导，来训练当前session模型（学生模型）。

- 蒸馏损失基于样本的三元组 (anchor, positive, negative) $ f_{j+1}(x_a)$, $f_j(x_a)$, and $f_j(x_n)$. 进行，其中正样本与锚点样本来自相同类别，负样本与锚点样本来自不同类别。

- 该损失旨在拉近正样本和锚点样本之间的距离，同时推远锚点样本和负样本之间的距离。

- 损失函数形式为：

  
  $$
  L_{m_{j;j+1}} = \frac{1}{n} \sum_{x_a} \left[ d_{j+1}^j(x_a, x_a) - d_{j+1}^j(x_a, x_n) + m \right]_+
  $$

  

  其中，

  $d_{j+1}^j(x, y) = \|f_{j+1}(x) - f_j(y)\|_2^2$，

  $m$ 是预设的边界（默认为 0.1），

  $f_j(\cdot)$ 和 $f_{j+1}(\cdot)$ 分别表示前一session和当前session的模型。

  损失函数确保了当前模型的输出与前一模型的嵌入空间保持一致性，特别是在相似和不相似样本之间。



### session内判别性损失（Intra-Session Discrimination Loss）

**设计思想与原理：**  

session内判别性损失的目的是在当前session内学习判别性特征，使得模型能够有效区分当前session中的新数据类别。在视觉搜索任务中，模型需要具备区分新添加数据类别的能力，因此在当前session数据中进行分类训练是必要的。session内判别性损失通过使用分类损失（如 softmax 交叉熵损失）来实现，确保模型可以在新的数据上进行有效的判别。

**技术细节：**  

- 使用 **Normalized Softmax（NSoftmax）损失**进行优化。该损失在分类层的输出上应用 L2 正则化，确保模型的输出嵌入向量具有统一的尺度，这有助于在视觉搜索任务中提高相似性度量的稳定性和准确性。

- 损失函数形式为：

  
  $$
  L_{c_{j+1}} = - \frac{1}{n} \sum_{i=1}^{n} \log\left(\frac{\exp(w_{y_i}^T f_{j+1}(x_i) / T)}{\sum_{k} \exp(w_k^T f_{j+1}(x_i) / T)}\right)
  $$

  

  其中，$x_i$ 是当前session中的数据样本，$y_i$ 是其对应的类别标签，$w_k$ 是分类层的权重向量，

  $f_{j+1}(x_i)$ 是通过当前session模型提取的 L2 归一化特征嵌入，

  $T$ 是温度参数（默认为 0.05）。

  整个表达式：

  
  $$
  \frac{\exp(w_{y_i}^T f_{j+1}(x_i) / T)}{\sum_{k} \exp(w_k^T f_{j+1}(x_i) / T)}
  $$
  

  是 **Softmax 函数的输出**，表示样本 $x_i$ 被预测为真实类别 $y_i$ 的概率。Softmax 函数将模型的输出（logits）转换为概率分布，使得所有类别的预测概率之和为 1。

  $\exp(w_{y_i}^T f_{j+1}(x_i) / T)$

  - **$f_{j+1}(x_i)$** 是样本 $x_i$ 的特征嵌入向量，表示通过模型第 $j+1$ 次会话训练后的神经网络提取的特征表示；
  - **$w_{y_i}^T$** 是与真实类别 $y_i$ 相关的权重向量；
  - **$\exp(\cdot)$** 是指数函数，应用于特征嵌入和权重的点积，放大其值；
  - **$T$** 是温度参数，用于调节 Softmax 函数的平滑度。较大的 $T$ 值使得概率分布更加平滑，较小的 $T$ 值使得分布更加尖锐。

  这一项 $\exp(w_{y_i}^T f_{j+1}(x_i) / T)$ 表示模型为样本 $x_i$ 在真实类别 $y_i$ 上计算出的“非归一化概率”（logit），通过 Softmax 转换为概率。

   $\sum_{k} \exp(w_k^T f_{j+1}(x_i) / T)$

  - **$w_k^T$** 是与类别 $k$ 对应的权重向量；
  - **$\sum_{k}$** 表示对所有类别的指数项求和，这个和代表所有类别的“非归一化概率”之和。

  这一项 $\sum_{k} \exp(w_k^T f_{j+1}(x_i) / T)$ 是 Softmax 分母，表示所有类别的非归一化概率的总和。Softmax 函数通过对所有类别的非归一化概率进行归一化，输出各类别的概率分布。

  

  

### 总体损失函数



整体损失函数由以下几个部分组成：**会话内区分损失**、**邻近会话模型一致性损失**和**会话间数据一致性损失**。整体损失函数的表达式如下：


$$
L = L_{\text{intra}} + \alpha \cdot L_{\text{coherence}} + \beta \cdot L_{\text{data\_coherence}}
$$


其中：

- $L_{\text{intra}}$ 是**会话内区分损失**（Intra-session Discrimination Loss），用于确保当前会话中新类别数据的区分性。
- $L_{\text{coherence}}$ 是**邻近会话模型一致性损失**（Neighbor-session Model Coherence Loss），用于保持新旧模型在特征空间中的一致性。
- $L_{\text{data \_   coherence}}$ 是**会话间数据一致性损失**（Inter-session Data Coherence Loss），通过重放旧数据的嵌入，保持新模型对旧类别的记忆。
- $\alpha$ 和 $\beta$ 是用于调整不同损失项的权重系数。

默认情况下，我们在实验中根据经验将$\alpha$设置为 $10$，将$\beta$ 设置为 $1$，并且在这项工作中使用cos距离进行检索

## 向后兼容的理解

这篇文章主要讲的是 特征空间中，新的 session 不断进来，然后要保持之前的 特征空间仍然可以使用，也就是所谓的向后兼容。**新训练的模型所产生的特征嵌入应与之前模型的嵌入保持一致**。也就是说，当引入新类别或新任务时，新模型的特征嵌入与旧模型的特征嵌入应能够共存，从而使得模型对先前类别或任务的检索和分类性能不下降，或者只受到较小的影响。

### 举例说明向后兼容性

假设有一个图片搜索系统，最初训练的模型支持对10个不同的动物类别（如猫、狗、鸟等）的图片进行检索，系统通过提取图片的特征嵌入来对图片进行索引和存储。用户可以通过上传一张图片来检索相似的动物图片。

#### 初始模型的使用：

- 初始模型已经训练好了，它可以提取每张图片的特征，并将它们嵌入到特征空间中。所有与这10个动物类别相关的图片都已经被索引好，系统可以高效地根据图片进行检索。

#### 增量学习阶段：

假设现在有了新的需求，用户想要增加5种新的动物类别（如马、牛、鹿等），此时就需要进行增量学习。**为了应对新的类别，模型必须进行重新训练，能够提取新类别图片的特征嵌入**。然而，这里出现了一个问题：**新的模型是否能够保持对旧类别（猫、狗、鸟等）的有效检索能力？**即使模型学会了新类别，是否仍然能够高效处理之前已经索引的图片？

- **向后兼容性解决的问题**：如果新模型和旧模型不兼容，用户可能会发现旧的动物类别（比如猫和狗）的检索结果变得很差，甚至无法正确识别旧图片。这就导致了“灾难性遗忘”的问题，旧类别的特征嵌入和新的特征嵌入之间出现了不兼容现象。
- **向后兼容性确保的效果**：通过设计向后兼容的机制，新模型不仅能够学习新的类别特征，还能够保持与旧模型的特征空间一致。**因此，系统不需要重新索引之前的所有图片**，检索时，用户上传的猫和狗图片依然能够准确地匹配到数据库中已有的相关图片。同时，新增的马和牛类别的检索功能也可以正常工作。

#### 举例总结：

在我们的例子中，向后兼容性保证了新模型在扩展系统功能（如增加新类别）的同时，能够与之前训练的模型保持一致。这样，用户既可以检索到旧类别的图片（如猫和狗），又能够检索到新类别的图片（如马和牛），并且整个系统不需要重新处理和索引原有的图片数据。这大大提高了系统的效率和性能。



## 思考与疑问

这篇文章提出了向后兼容的特征，这样首先就是不需要再重新来训练，其次解决了灾难性遗忘问题。

但其实有一个问题，特征随着加入的类越来越多，那么特征空间肯定会发生变化吧， 这种向后兼容的设置是否还有效，另外，这里是依赖于一个 重放嵌入（replayed embedding）和使用少量回放数据机制，也就是说不光是存储了数据，还存储了特征来保证这个长期过程中的稳定性。

还有一个点是这种向后对齐某种程度上是不是牺牲了新的类的表现，但可能我们的衡量标准是所有的类的平均检测效果，所以这种牺牲是可以接受的？

**如何应对兼容性成本？**

就像你提到的，**这种兼容机制会带来代价**。但研究人员已经提出了一些方法来缓解这一问题：

- **特征重放机制（Feature Replay）**：通过保存旧类的特征嵌入，而不是保存所有旧数据样本，能够在保持一定兼容性的同时减少计算和存储的开销。这样避免了必须重新处理旧类的全部数据。
- **弹性网络方法**：一些方法，如弹性权重整合（EWC），通过为旧类分配重要性权重来保护与旧任务相关的权重。这种方式可以在不大幅增加计算量的前提下，保持兼容性。
- **动态扩展模型**：在一些更加灵活的模型中，可以动态增加模型的容量（如通过网络剪枝或模型扩展），从而为新类别提供更多的参数资源，同时减轻旧类别嵌入的漂移。这类方法可以在一定程度上缓解特征空间饱和的问题。

**总结与展望**

综上所述，向后兼容性在持续学习中是一个有效但存在挑战的机制。**初期的兼容性效果较好**，但随着类别增多和特征空间饱和，**长期兼容性会逐渐变得困难**。与 Windows 向后兼容一样，维护这种兼容性确实有代价，但研究界已经在努力提出各种机制来降低这种成本（如特征重放、知识蒸馏、模型扩展等）。



# CL2R: Compatible Lifelong Learning Representations 

## 论文信息

**标题**: CL2R: Compatible Lifelong Learning Representations  

## 设定

本文研究了终身学习（Lifelong Learning, LL）中的兼容表示问题，特别是在视觉搜索任务中，如何在增量学习过程中保持特征表示的兼容性。

为了在增量学习过程中实现兼容特征表示，本文提出了一种新的训练程序，鼓励所学习特征的全局和局部平稳性。平稳性是指特征的统计性质不会随着时间而改变，这使得新学习的特征能够与之前学习的特征互操作。通过这种方式，模型能够在不遗忘旧特征的情况下，逐步学习新特征。

### 目标

目标是设计一个训练过程来学习模型 $ \phi_t $，使得经过该模型变换的任何查询图像都可以通过某种距离函数 $ \text{dist} : \mathbb{R}^d \times \mathbb{R}^d \rightarrow \mathbb{R}^+ $ 执行视觉搜索，从而识别出与查询特征 $F_Q$ 最近的特征 $F_G$，而不会遗忘先前的特征表示，也无需重新计算 $F_G = { f \in \mathbb{R}^d | f = \phi_t(x), \forall x \in I_G }$（即不需要重新索引）。如果这一点成立，那么生成的表示 $ \phi_t $ 就被认为与 $ \phi_k $ 是终身兼容的。CL2R 问题的主要挑战在于同时缓解灾难性遗忘并学习一种与先前模型兼容的表示。

### 创新点

1. **兼容终身学习表示（CL2R）**: 提出了一个新概念，即在终身学习范式下进行兼容表示学习，旨在解决灾难性遗忘和特征兼容性之间的冲突。
2. **平稳性训练策略**: 提出了一种新的训练程序，鼓励全局和局部平稳性，通过回放策略（rehearsal）和特征平稳性联合解决灾难性遗忘和特征兼容性问题。
3. **新评估指标**: 定义了一套新的指标来专门评估在灾难性遗忘下的兼容表示学习性能。

## 方法

### 方法的设计思想

CL2R（Compatible Lifelong Learning Representations）方法的设计思想旨在解决增量学习中灾难性遗忘（catastrophic forgetting）和特征表示兼容性之间的冲突。其核心思想是通过引入全局和局部平稳性，来保证在学习新任务时，新旧特征表示能够保持兼容性。该方法依赖于以下几个关键设计思想：

1. **全局平稳性（Global Stationarity）**:  

   **全局稳定性**是 CL2R 提出的一种方法，旨在确保新旧任务的特征表示在**全局特征空间中保持一致性**，即从整体上限制新旧模型生成的特征表示发生显著变化。

   **具体做法**：

   - **固定分类器原型（Fixed Classifier Prototype）**：CL2R 引入了一个固定的分类器原型——**Simplex固定分类器**。该分类器的原型向量在特征空间中保持不变，用于引导新模型的特征方向与旧模型的特征方向保持一致。
   - **特征方向对齐**：通过固定的分类器原型，CL2R 强制新任务的特征向量与旧任务特征向量的方向对齐，从而减少特征方向的偏移。由于特征空间中的特征向量表示的是样本的高维嵌入，这一方法确保了新旧模型特征空间在宏观上保持一致性。

   **作用**：

   - 通过引入全局特征的稳定性约束，CL2R 保证了不同任务的特征表示在全局特征空间中的方向保持一致，从而减少特征表示的大规模漂移。全局稳定性约束尤其适合处理新旧任务之间特征表示可能存在的显著差异。

2. **局部平稳性（Local Stationarity）**:  

   除了全局上的特征对齐，CL2R 还提出了**局部稳定性**机制，旨在保证新任务学习时，每个样本的特征在新旧模型中的局部表示保持一致。

   **具体做法**：

   - 特征蒸馏损失（Feature Distillation Loss）

     ：CL2R 使用特征蒸馏机制来保证局部特征一致性。特征蒸馏是通过让新模型模仿旧模型在特定样本上的特征表示来实现的。对于每个样本 $x_i$，新模型的特征表示 $f_{new}(x_i)$ 需要与旧模型的特征表示 $f_{old}(x_i)$ 保持一致，公式如下：

     
     $$
     L_{distill} = \frac{1}{N} \sum_{i=1}^{N} \| f_{new}(x_i) - f_{old}(x_i) \|^2
     $$
     

     通过最小化新旧模型特征向量之间的 L2 范数差异，确保新模型在局部样本上的特征与旧模型保持一致。

   **作用**：

   - **局部特征稳定性**确保了每个样本在特征空间中的局部嵌入不会发生显著漂移。即使模型在学习新任务时，个别样本的特征表示也能够与旧任务中的表示保持一致，从而增强特征表示的兼容性。局部稳定性可以减少对单一样本的灾难性遗忘，有助于提升整体兼容性。

3. **回放策略（Rehearsal Strategy）**:  为了进一步增强模型对旧任务的记忆能力，CL2R 还结合了**回放策略**，即在训练新任务时，模型还会使用部分旧任务的样本来帮助保持旧任务特征的稳定性。通过使用情景记忆（episodic memory），保存之前任务中的部分样本，并在训练新任务时使用这些样本。这样可以在增量学习过程中，通过重新使用这些样本来强化对旧任务的记忆，从而缓解灾难性遗忘。

   **具体做法**：

   - **记忆库（Memory Buffer）**：CL2R 维护一个记忆库，其中存储了旧任务中的一部分样本。每次训练新任务时，模型不仅使用新任务的数据，还会从记忆库中采样旧任务的样本，并将其与新任务一起训练。
   - **联合训练**：通过同时使用新任务样本和记忆库中的旧任务样本进行训练，模型能够在学习新任务时，保留对旧任务的记忆。这样可以有效减少灾难性遗忘，确保新模型与旧模型特征之间的兼容性。

   **作用**：

   - **回放策略**通过结合旧任务样本和新任务样本进行联合训练，进一步提升了特征表示的兼容性和稳定性。特别是在应对长序列的增量学习任务时，回放策略可以有效减少灾难性遗忘。

### 原理

CL2R方法的核心原理在于确保特征表示的平稳性，这使得新旧特征表示在特征空间中具有较高的兼容性。具体来说，CL2R利用以下两种主要机制来实现兼容性：

1. **全局特征平稳性**:  使用一个固定的分类器原型（$d$-Simplex Regular Polytope）来约束特征表示，使得学习的特征始终与固定的原型对齐。通过这种方式，可以实现特征表示的全局平稳性，从而保证不同任务间特征表示的兼容性。

2. **局部特征平稳性**:  特征蒸馏（Feature Distillation）用于在当前模型与前一个模型之间保持特征表示的一致性。通过最小化新旧模型在特征空间的差异，CL2R方法有效地防止了由于模型更新而导致的特征表示变化，从而实现了局部特征平稳性。

### 与其他方法的区别

CL2R方法与其他增量学习方法的主要区别在于其独特的特征表示兼容性设计：

- **传统增量学习方法（如LwF, LUCIR, BiC, PODNet）**：这些方法主要关注减少灾难性遗忘，通过知识蒸馏和经验重放（experience replay）等策略来保持对旧任务的记忆，但它们并未显式关注特征表示的兼容性，**通常在特征空间中会有显著的变化**。
- **FAN 和 BCT 方法**：这些方法试图在特征空间中保持兼容性，但通常**通过固定模型或映射函数的方式来实现**。然而，它们的性能会随着任务数量的增加而下降，因为它们在适应新任务的过程中难以有效处理大量的特征映射变化。
- **CL2R 方法**：与上述方法不同，CL2R不仅通过知识蒸馏来缓解灾难性遗忘，还通过全局和局部平稳性设计来确保新旧特征表示的兼容性。这使得CL2R方法在不需要重新索引的情况下实现高效的增量学习，尤其适用于大规模视觉搜索任务。

### 技术细节

1. **全局平稳性训练策略**

   **固定分类器原型**: 使用$d$-Simplex正多面体作为固定分类器原型，定义为

   
   $$
   W = \{e_1, e_2, \ldots, e_{d-1}, \alpha \sum_{i=1}^{d-1} e_i\}，
   $$
   

   其中 $\alpha = 1 - \sqrt{\frac{d+1}{d}}$ ， $e_i$ 是 $R^{d-1}$ 中的标准基。

   **损失函数**: CL2R使用改进的交叉熵损失，公式如下：

   
   $$
   L_t = - \frac{1}{|T_t|} \sum_{x \in T_t} \log \left( \frac{\exp(w_{y_i}^\top \cdot \phi(x))}{\sum_{j \in K_s} \exp(w_j^\top \cdot \phi(x)) + \sum_{j \in K_u} \exp(w_j^\top \cdot \phi(x))} \right)
   $$

   

   其中，

   $T_t$是当前任务的训练集，

   $K_s$是到当前任务为止已经学习的类别集合，

   $K_u$是未来 未见过的类别集合

   $w^T_{(\cdot)}$  是固定分类器$W$ 的类原型

   $W$ 是固定分类器的权重矩阵，该分类器在模型训练期间不进行学习

   $y_i$ 是有监督学习的标签

   $\phi$ 是将查询图像(query image)转换为特征向量 (feature vectors)

   

   

   

2. **局部平稳性训练策略**

   - **特征蒸馏损失（Feature Distillation Loss, FD）**: 用于在局部特征空间中保持新旧模型之间的特征表示一致性。FD损失在每个任务$t$上，仅在情景记忆$M_t$中存储的样本上进行评估：

   $$
   L_{\text{FD}}^M = \frac{1}{|M_t|} \sum_{x_i \in M_t} \left( 1 - \frac{\phi_t(x_i) \cdot \phi_{t-1}(x_i)}{\|\phi_t(x_i)\| \|\phi_{t-1}(x_i)\|} \right)
   $$

   其中，$\phi_t$表示当前任务的模型，$\phi_{t-1}$表示前一个任务的模型。

   

3. **最终损失函数**

   - **综合损失函数**: 最终优化的损失函数是全局和局部对齐提供的两个损失之和：

   $$
   L = L_t + \lambda L_{\text{FD}}^M
   $$

   其中，$\lambda$用于平衡全局和局部对齐的贡献。

## 实验

### 实验设置与参数

- **数据集**: 实验在多个基准数据集上进行，包括 CIFAR10, ImageNet201, ImageNet100, Labeled Face in the Wild (LFW) 和 IJB-C。
- **模型**: 使用 ResNet-32, ResNet-18 和 ResNet-50 作为特征提取器，分别在不同的任务中进行评估。
- **优化器**: 使用 SGD 优化器，初始学习率为 0.1，权重衰减为 2×10^-4。学习率在特定 epoch 后衰减。
- **训练过程**: 训练程序基于增量微调策略（incremental fine-tuning），每个任务训练多个 epoch，使用回放策略以缓解灾难性遗忘。

### 对比方法

本文将所提出的方法与多种现有的增量学习方法进行比较，包括：

- **Learning without Forgetting (LwF)**: 通过知识蒸馏来防止遗忘。
- **LUCIR**: 使用特征蒸馏减少灾难性遗忘的增量学习方法。
- **BiC**: 通过学习额外的线性层来重新校准输出概率。
- **PODNet**: 使用基于空间的蒸馏损失来约束每个残差块之后的中间特征统计。
- **FOSTER**: 解决兼容性问题的方法，通过训练线性层将不断增长的特征向量映射到固定维度。
- **FAN** 和 **BCT**: 提供显式机制来解决特征兼容性问题的方法。

### 结果与结论

实验结果表明，所提出的 CL2R 训练程序在多个基准数据集和不同的增量学习任务下都表现出色，相较于基线和最新的研究方法，显著减少了灾难性遗忘，同时保持了高水平的特征兼容性。尤其在面对多任务学习时，CL2R 训练程序能够有效地学习兼容特征表示，而无需频繁重新索引图库

### 结论

CL2R方法通过设计特征表示的全局和局部平稳性，成功实现了在增量学习过程中的特征兼容性。相较于其他方法，CL2R不仅有效减少了灾难性遗忘，还在大规模视觉搜索任务中无需重新索引就实现了高效的增量学习。这种方法的创新设计为未来的终身学习和特征表示兼容性研究提供了新的思路和工具。







# Simplex 



### Simplex 固定分类器是什么？

**Simplex 固定分类器（Simplex Fixed Classifier）** 是 CL2R 提出的一个关键机制，用于在持续学习中保持**全局特征稳定性（Global Stationarity）**。它通过一个固定的、几何上对称的分类器原型，来约束特征空间中的特征表示，使得新旧任务的特征能够在全局方向上保持一致。

在具体实现中，Simplex 固定分类器通过构造一个“Simplex”几何结构，其中每个类的原型向量在特征空间中以对称方式排列。这种结构确保了新旧任务特征嵌入方向的一致性，减少了特征空间的漂移。

### 什么是 Simplex 几何结构？

**Simplex** 是一个几何学术语，表示一种**对称的几何形状**。在 $d$ 维空间中，Simplex 是由 $d+1$ 个顶点构成的多面体，其特点是这些顶点在几何上是对称的，且每两个顶点之间的距离相等。

在 Simplex 固定分类器中，每个类的特征原型向量（prototype vector）被设计成一个 Simplex 结构，这意味着：
- 每个类的原型向量在特征空间中以对称的方式排列；
- 不同类的原型向量之间的角度保持恒定，从而在空间中形成均匀分布。

### Simplex 固定分类器的工作原理

在 CL2R 中，Simplex 固定分类器通过固定这些几何对称的类原型向量来引导新任务的特征表示，使它们的方向与旧任务保持一致。这种做法的主要目的是通过确保特征向量的方向稳定，减少新任务特征对旧任务特征空间的干扰，进而实现全局特征稳定性。

#### 具体实现方式：

1. **固定类原型向量**：
   Simplex 分类器的每个类原型向量 $\mu_i$ 被固定为位于 Simplex 几何形状的一个顶点。通过这样设计，CL2R 中所有的类原型向量在训练过程中保持不变，即不随模型的更新或新任务的加入而改变。这种设计确保了特征空间中的全局几何结构在整个持续学习过程中保持稳定。

2. **新任务特征对齐**：
   在训练新任务时，新任务的特征表示 $f_{new}(x)$ 会被引导与 Simplex 分类器的固定原型向量对齐。这意味着新任务的特征表示必须符合原有几何结构的方向，从而避免新任务特征方向的偏移。

3. **全局特征方向一致性**：
   由于 Simplex 分类器的原型向量是对称且固定的，CL2R 能够确保新旧任务特征的方向在特征空间中保持一致。这样，即使新任务学习到了新的特征，整体特征空间的方向性依然被保持，减轻了特征漂移的问题。

#### 数学形式：

假设 $C$ 是类的数量，Simplex 分类器的类原型向量 $\mu_1, \mu_2, \dots, \mu_C$ 是对称排列的，表示每个类的中心。对于一个输入样本 $x_i$，模型生成的特征向量 $f(x_i)$ 被引导与 Simplex 分类器中的某一个类原型 $\mu_k$ 对齐。整个过程通过最小化以下损失来实现：

$$
L_{global} = \sum_{i} \| f(x_i) - \mu_{y_i} \|^2
$$

其中，$y_i$ 是样本 $x_i$ 的真实标签，$\mu_{y_i}$ 是该样本所属类别的原型向量。

通过最小化这个损失函数，模型强制新生成的特征与对应类的固定原型对齐，从而确保特征方向的稳定性。

### 为什么原型向量保持不变？

在 CL2R 中，**Simplex 分类器的原型向量保持不变**，是为了确保整个特征空间的全局方向在引入新任务时不会发生显著变化。主要原因和效果如下：

1. **减少特征空间的漂移**：
   在持续学习过程中，如果每次引入新任务时都调整类的原型向量，那么特征空间会发生较大变化。这会导致模型在处理旧任务时产生灾难性遗忘。因此，通过固定原型向量，可以确保特征空间的全局几何结构保持稳定，减少新任务对旧任务的干扰。

2. **特征对齐和一致性**：
   原型向量的固定允许新任务的特征表示与旧任务的特征表示保持方向一致。即使模型在学习新任务时生成了新的特征，这些特征也会被引导与原有的固定方向对齐，从而确保特征的一致性。

3. **对称性带来的稳健性**：
   Simplex 分类器的几何对称性确保了每个类的原型向量之间的角度是对称的，并且这种对称结构不会因为新任务的引入而被破坏。这种对称性使得特征空间在全局上更加稳健和一致，有助于提升模型的鲁棒性。

### 如何实现 Simplex 分类器的固定原型？

要实现 Simplex 分类器的固定原型，可以通过以下步骤：

1. **构造 Simplex 原型向量**：
   在 $d$ 维空间中，选择 $C$ 个类原型 $\mu_1, \mu_2, \dots, \mu_C$，使得这些向量之间的角度均匀分布。几何上，这可以通过解等距离问题（等距顶点）来构造 Simplex 结构。每个原型向量的长度可以标准化为单位向量。

2. **固定原型向量**：
   一旦类原型向量构造完成，便在整个训练过程中固定不变。无论是旧任务还是新任务，所有任务的特征向量都会与这些固定的原型向量对齐。

3. **特征对齐损失**：
   在模型训练中，通过最小化样本特征与对应类原型向量之间的差异来进行训练。这样，即使学习新任务，特征空间的整体方向和结构依然被保持。

### 总结

**Simplex 固定分类器**是 CL2R 提出的一个关键机制，用于保持特征空间的全局稳定性。它通过几何对称的 Simplex 结构来固定分类器的类原型向量，确保新旧任务的特征表示在全局方向上保持一致性。这种方法的主要优点在于：
- **减少特征漂移**：通过固定类原型向量，确保新旧任务特征的全局方向一致，从而减少特征空间的漂移。
- **特征表示兼容性**：无论是旧任务还是新任务，所有任务的特征都与这些固定原型向量对齐，增强了特征表示的兼容性。

这种方法为持续学习中的特征表示提供了全局一致性，有助于在引入新任务时减少灾难性遗忘，同时保持旧任务的性能稳定。

1bd93c0ca05c63707aee3cf63ab2f40ddda7cbb9 
